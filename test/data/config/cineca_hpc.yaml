# Logging
vectoria_logs_dir: ~/vectoria_logs
log_level: DEBUG
langchain_tracking: null
system_prompts_lang: eng

# Preprocessing
pp_multiprocessing: true
pp_steps: 
  - name: extract_text_from_docx_file
    dump_doc_structure_on_file: true
    regexes_for_metadata_extraction: []

  - name: remove_header
    regex: null
  
  - name: remove_footer
    regex: null

  - name: remove_multiple_spaces
    regex: null

  - name: replace_ligatures
    regex: null
  
  - name: remove_bullets
    regex: null

  - name: recursive_character_text_splitter
    chunk_size: 512
    chunk_overlap: 128
    separators: ["\n\n", "\n", " ", ""]
    is_separator_regex: [false, false, false, false]
    dump_chunks_on_file: true
  
vector_store:
  name: faiss
  model_name: /leonardo_work/PhDLR_prod/bge-m3 # CINECA
  device: cuda
  normalize_embeddings: false

retriever:
  enabled: true
  name: faiss
  search_type: 'mmr'
  top_k: 5
  fetch_k: 5
  lambda_mult: 0.5

reranker:
  enabled: false
  reranked_top_k: 3
  inference_engine:
    name: huggingface
    url: null
    api_key: null
    # model_name: /leonardo_work/PhDLR_prod/bge-reranker-v2-gemma # from SSD
    model_name: /dev/shm/bge-reranker-v2-gemma # from RAM
    device: cuda
    load_in_4bit: true
    load_in_8bit: false
    max_new_tokens: 150
    trust_remote_code: false
    device_map: null
    temperature: 0.1

full_paragraphs_retriever:
  enabled: false
  
chat_history:
  enabled: false

# QA agent
inference_engine:
  name: huggingface
  url: null
  api_key: null
  model_name: /dev/shm/Meta-Llama-3.1-8B-Instruct # RAM 8B
  device: cuda
  load_in_4bit: true
  load_in_8bit: false
  max_new_tokens: 150
  trust_remote_code: false
  device_map: auto
  temperature: 0.1

# Evaluation (no VLLM on LeoHPC)
evaluation:
  tool: ragas
  inference_engine:
    name: huggingface
    # model_name: hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4
    model_name:  /dev/shm/Meta-Llama-3.1-8B-Instruct # RAM 8B
    url: http://localhost:8899/v1
    api_key: abcd
    device: cuda
    load_in_8bit: true
    max_new_tokens: 150
    trust_remote_code: false
  #embeddings_engine:
  #  name: vllm
  #  model_name: BAAI/bge-multilingual-gemma2
  #  url: http://localhost:8898/v1
  #  api_key: abcd

# Evaluation
# evaluation_tool: ragas
# evaluation_engine:
#   name: huggingface
#   url: null
#   api_key: null
#   model_name: /dev/shm/Meta-Llama-3.1-8B-Instruct # RAM 8B
#   device: cuda
#   load_in_8bit: true
#   max_new_tokens: 150
#   trust_remote_code: false
