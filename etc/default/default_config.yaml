
 # Logging
vectoria_logs_dir: ~/vectoria_logs
log_level: DEBUG
langchain_tracking: null

# Preprocessing
pp_multiprocessing: true
pp_steps: 
  - name: extract_text_from_docx_file
    filter_paragraphs: ["1", "2", "3"]
    log_in_folder: ~/vectoria_logs/docs_structure

  - name: remove_header
    regex: 'PROCEDURA\s+PRO\d+\s+-P-IT\s+REV\.\s+\d+\s+PRO\d\s+\d+-P-IT\s+REV\.\s+\d+\s+SELEZIONE,\s+AUTORIZZAZIONE\s+E\s+QUALIFICA\s+DEI\s+FORNITORI\s+' 
  
  - name: remove_footer
    regex: 'Template:\s+QUA\d+\s+-T-CO\s+it\s+rev\d+\s+©\s+Copyright\s+Selex\s+ES\s+S\.p\.A\.\s+\d+\s+\d+\s+–\s+Tutti\s+i\s+diritti\s+riservati\s+Pag\.\s+\d+\s+di\s+\d+'

  - name: remove_multiple_spaces
    regex: null

  - name: replace_ligatures
    regex: null
  
  - name: remove_bullets
    regex: null

  - name: recursive_character_text_splitter
    chunk_size: 1024
    chunk_overlap: 256
    separators: ["\n\n", "\n", " ", ""]
    is_separator_regex: [false, false, false, false]
    log_in_folder: ~/vectoria_logs/docs_structure


# Vector store
# hf_embedder_model_name: BAAI/bge-m3 # LEO
hf_embedder_model_name: /leonardo_work/PhDLR_prod/bge-m3 # CINECA
embedder_device: cuda
normalize_embeddings: false

# QA agent
retriever_top_k: 5
retriever_search_type: 'mmr'
retriever_fetch_k: 5
retriever_lambda_mult: 0.5
chat_history: false
system_prompts_lang: it

# Inference engine
inference_engine:
  name: 'huggingface'
  url: null
  api_key: null
  # model_name: meta-llama/Meta-Llama-3.1-8B-Instruct # LEO
  # model_name: /leonardo_work/PhDLR_prod/meta-llama/Meta-Llama-3.1-8B-Instruct # CINECA
  # model_name: /leonardo_scratch/large/userinternal/aproia00/Meta-Llama-3-70B-Instruct # TEST WITH 70B
  # model_name: /leonardo_scratch/fast/PhDLR_prod/Meta-Llama-3.1-8B-Instruct # FAST
  # model_name: /dev/shm/Meta-Llama-3.1-8B-Instruct # RAM 8B
  model_name: /dev/shm/Meta-Llama-3.1-70B-Instruct

  device: cuda
  load_in_8bit: true
  max_new_tokens: 150