
 # Logging
vectoria_logs_dir: ~/vectoria_logs
log_level: DEBUG
langchain_tracking: false
system_prompts_lang: eng

langfuse:
  enabled: true
  host: http://localhost:3000
  public_key: pk-lf-972ecefa-e6f7-4800-817f-014b42b86414
  secret_key: sk-lf-7c87e30d-3a39-4bcc-800e-6c876764ef66

data_ingestion:
  multiprocessing: true
  
  extraction:
    format: docx
    dump_doc_structure_on_file: true
    regexes_for_metadata_extraction:
      - name: DOC_ID
        pattern: '^Document Title'

  regexes_for_replacement:
    - name: remove_multiple_spaces
      pattern: '[ \t]{2,}'
      replace_with: ' '
    - name: remove_bullets
      pattern: '^\s*[\u2022\u25AA\u27A2]\s*'
      replace_with: ''
    - name: remove_ligature_st
      pattern: 'ï¬†'
      replace_with: 'st'

  chunking:
    chunk_size: 512
    chunk_overlap: 256
    separators: ["\n\n", "\n", " ", ""]
    is_separator_regex: [false, false, false, false]
    dump_chunks_on_file: true

vector_store:
  name: faiss
  model_name: </PATH/TO/INSTALLDIR/EMBEDDER_MODEL> (e.g. BAAI/bge-m3)
  device: cuda
  normalize_embeddings: false

retriever:
  enabled: true
  k: 5
  search_type: 'mmr'
  fetch_k: 5
  lambda_mult: 0.5

reranking:
  enabled: false
  rerank_k: 3
  inference_engine:
    name: huggingface
    url: null
    api_key: null
    model_name: </PATH/TO/INSTALLDIR/RERANKER_MODEL> (e.g. BAAI/bge-reranker-v2-gemma)
    device: cuda
    load_in_4bit: false
    load_in_8bit: false
    max_new_tokens: 150
    trust_remote_code: false
    device_map: auto
    temperature: 0.1

full_paragraphs_retriever:
  enabled: false

inference_engine:
  name: huggingface
  url: null
  api_key: null
  model_name: </PATH/TO/INSTALLDIR/INFERENCE_ENGINE> (e.g. meta-llama/Meta-Llama-3.1-8B-Instruct)
  device: cuda
  load_in_8bit: false
  max_new_tokens: 150
  trust_remote_code: false
  device_map: auto
  temperature: 0.1

evaluation:
  tool: ragas
  inference_engine:
    name: vllm
    model_name: </PATH/TO/INSTALLDIR/INFERENCE_ENGINE> (e.g. hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4)
    url: null
    api_key: null
  embeddings_engine:
    name: vllm
    model_name: </PATH/TO/INSTALLDIR/EMBEDDER_MODEL> (e.g. BAAI/bge-multilingual-gemma2)
    url: null
    api_key: null
