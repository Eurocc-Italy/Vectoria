# Logging
vectoria_logs_dir: ~/vectoria_logs
log_level: DEBUG
langchain_tracking: null
system_prompts_lang: {{ language }}

data_ingestion:
  multiprocessing: true
  
  extraction:
    format: {{ format }}
    dump_doc_structure_on_file: true
    regexes_for_metadata_extraction:
      - name: DOC_ID
        pattern: '^Document Title'

  regexes_for_replacement:
    - name: remove_multiple_spaces
      pattern: '[ \t]{2,}'
      replace_with: ' '
    - name: remove_bullets
      pattern: '^\s*[\u2022\u25AA\u27A2]\s*'
      replace_with: ''
    - name: remove_ligature_st
      pattern: 'ﬆ'
      replace_with: 'st'
    - name: replace_fi
      pattern: 'ﬁ'
      replace_with: 'fi'
    - name: replace_fl
      pattern: 'ﬂ'
      replace_with: 'fl'
    - name: replace_ffi
      pattern: 'ﬃ'
      replace_with: 'ffi'
    - name: replace_ffl
      pattern: 'ﬄ'
      replace_with: 'ffl'
    - name: replace_ft
      pattern: 'ﬅ'
      replace_with: 'ft'
    - name: replace_st
      pattern: 'ﬆ'
      replace_with: 'st'
    - name: replace_AA
      pattern: 'Ꜳ'
      replace_with: 'AA'
    - name: replace_AE
      pattern: 'Æ'
      replace_with: 'AE'
    - name: replace_aa
      pattern: 'ꜳ'
      replace_with: 'aa'

  chunking:
    chunk_size: 512
    chunk_overlap: 256
    separators: ["\n\n", "\n", " ", ""]
    is_separator_regex: [false, false, false, false]
    dump_chunks_on_file: true

vector_store:
  name: faiss
  model_name: {{ install_path }}/embedder_model
  device: cuda
  normalize_embeddings: false

retriever:
  enabled: true
  top_k: 5
  search_type: 'mmr'
  fetch_k: 5
  lambda_mult: 0.5

reranker:
  enabled: true
  reranked_top_k: 3
  inference_engine:
    name: huggingface
    url: null
    api_key: null
    model_name: /dev/shm/reranker_model
    device: cuda
    load_in_4bit: {{ reranker_4bit }}
    load_in_8bit: {{ reranker_8bit }}
    max_new_tokens: 150
    trust_remote_code: false
    device_map: null
    temperature: 0.1

full_paragraphs_retriever:
  enabled: false

chat_history:
  enabled: false

# Inference engine
inference_engine:
  name: 'huggingface'
  url: null
  api_key: null
  model_name: /dev/shm/inference_engine 
  device: cuda
  load_in_4bit: {{ inference_4bit }}
  load_in_8bit: {{ inference_8bit }}
  max_new_tokens: 150
  trust_remote_code: true
  device_map: auto
  temperature: 0.1

evaluation_tool: ragas
evaluation_engine:
  name: huggingface
  url: null
  api_key: null
  model_name: /dev/shm/inference_engine 
  device: cuda
  load_in_8bit: {{ inference_8bit }}
  max_new_tokens: 150
  trust_remote_code: false